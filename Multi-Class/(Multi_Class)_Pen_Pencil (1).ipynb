{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {
        "id": "crG7Lho1xhG_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "file_path = '/content/Multi_Class.zip'\n",
        "\n",
        "new_file = 'Multiclass'\n",
        "\n",
        "with zipfile.ZipFile(file_path,'r') as zip_ref:\n",
        "  zip_ref.extractall(new_file)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BtZW8Gj_xttG"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ModelClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelClassifier, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "                      nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "                      nn.BatchNorm2d(16),\n",
        "                      nn.ReLU(),\n",
        "                      nn.MaxPool2d(2,2) #64\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "                      nn.BatchNorm2d(32),\n",
        "                      nn.ReLU(),\n",
        "                      nn.MaxPool2d(2,2) #32\n",
        "        # self.conv2_drop = nn.Dropout2d()\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(nn.Conv2d(32,64,kernel_size=3, padding=1),\n",
        "                      nn.BatchNorm2d(64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.MaxPool2d(2,2) #16\n",
        "        )\n",
        "        # self.conv3_drop = nn.Dropout2d()\n",
        "        self.conv4 = nn.Sequential(nn.Conv2d(64,128,kernel_size=3, padding=1),\n",
        "                     nn.BatchNorm2d(128),\n",
        "                     nn.ReLU(),\n",
        "                     nn.MaxPool2d(2,2) #8\n",
        "        )\n",
        "        self.drop = nn.Dropout(0.5)\n",
        "        # Calculate the flattened size dynamically\n",
        "        # Create a dummy tensor with the expected input dimensions (batch_size=1, channels=1, height=28, width=28)\n",
        "        # The size needs to match the input image size after transformations (28x28 grayscale in your case)\n",
        "        dummy_input = torch.randn(16, 3, 128, 128)\n",
        "\n",
        "        # self.eval()\n",
        "        # # Pass the dummy input through the convolutional and pooling layers\n",
        "        # # Ensure the operations match the forward pass up to the point of flattening\n",
        "        # x = F.relu(self.bn1(F.max_pool2d(self.conv1(dummy_input), 2)))\n",
        "        # x = F.relu(self.bn2(F.max_pool2d(self.conv2(x), 2)))\n",
        "        # x = F.relu(self.bn3(self.conv3(x)))\n",
        "        # x = F.relu(self.bn4(self.conv4(x)))\n",
        "        # self.train()\n",
        "        x = self.conv1(dummy_input)\n",
        "        x = self.conv2(x)\n",
        "        # # Note: conv2_drop is not applied when calculating the size\n",
        "        # x = F.relu(self.bn2(F.max_pool2d(x, 2)))\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        # Calculate the number of features before flattening\n",
        "        self._to_linear = x.numel() // x.shape[0] # Divide by batch size\n",
        "\n",
        "        self.dense = nn.Linear(self._to_linear, 300)\n",
        "        self.out = nn.Linear(300, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "      # Layer 1\n",
        "        # x = F.relu(self.bn1(F.max_pool2d(self.conv1(x), 2)))\n",
        "        # # Layer 2\n",
        "        # x = self.conv2(x)\n",
        "        # x = self.conv2_drop(x)\n",
        "        # x = F.relu(self.bn2(F.max_pool2d(x, 2)))\n",
        "        # # Layer 3\n",
        "        # x = self.conv3(x)\n",
        "        # x = self.conv3_drop(x)\n",
        "        # x = F.relu(self.bn3(x))\n",
        "        # # Layer 4\n",
        "        # x = self.conv4(x)\n",
        "        # x = self.conv4_drop(x)\n",
        "        # x = F.relu(self.bn4(x))\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        # x = self.drop(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        # x = x.view(-1, self._to_linear)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.drop(x)\n",
        "        # Layer 5\n",
        "        x = F.relu(self.dense(x))\n",
        "        x = self.out(x)\n",
        "\n",
        "        return x"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "QeS_O3V56hrI"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class ModelClassifier(nn.Module):\n",
        "#   def __init__(self):\n",
        "#     super(ModelClassifier,self).__init__()\n",
        "#     self.conv1 = nn.Conv2d(1,32,kernel_size=5)\n",
        "#     self.bn1 = nn.BatchNorm2d(32)\n",
        "#     self.conv2 = nn.Conv2d(32,64,kernel_size=5)\n",
        "#     self.bn2 = nn.BatchNorm2d(64)\n",
        "#     self.conv2_drop = nn.Dropout2d()\n",
        "#     self.dense = nn.Linear(320,100)\n",
        "#     self.out = nn.Linear(100,2)\n",
        "\n",
        "#             # Calculate the flattened size dynamically\n",
        "#         # Create a dummy tensor with the expected input dimensions (batch_size=1, channels=1, height=28, width=28)\n",
        "#         # The size needs to match the input image size after transformations (28x28 grayscale in your case)\n",
        "#     dummy_input = torch.randn(1, 1, 28, 28)\n",
        "#         # Pass the dummy input through the convolutional and pooling layers\n",
        "#     x = F.relu(self.bn1(F.max_pool2d(self.conv1(dummy_input), 2)))\n",
        "#     x = self.conv2(x)\n",
        "#     x = F.relu(self.bn2(F.max_pool2d(x, 2)))\n",
        "#         # Calculate the number of features before flattening\n",
        "#     self._to_linear = x.numel() // x.shape[0] # Divide by batch size\n",
        "\n",
        "#     self.dense = nn.Linear(self._to_linear, 100)\n",
        "#     self.out = nn.Linear(100, 2)\n",
        "\n",
        "#   def forward(self,x):\n",
        "#     x = F.relu(self.bn1(F.max_pool2d(self.conv1(x),2)))\n",
        "#     x = self.conv2(x)\n",
        "#     x = self.conv2_drop(x)\n",
        "#     x = F.relu(self.bn2(F.max_pool2d(x,2)))\n",
        "#     x = x.view(-1,self._to_linear)\n",
        "#     x = F.relu(self.dense(x))\n",
        "#     x = self.out(x)\n",
        "\n",
        "#     return x"
      ],
      "metadata": {
        "id": "2fmHR8FhyS5n"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z078uguQ2L-I"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.Grayscale(),  # if not already grayscale\n",
        "#     transforms.Resize((32, 32)),  # resize if needed\n",
        "# ])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    # transforms.Grayscale(),  # if not already grayscale\n",
        "    transforms.Resize((128, 128)),  # resize if needed\n",
        "    # transforms.RandomResizedCrop(size=128,scale=(0.8,1.0)),\n",
        "    transforms.RandomHorizontalFlip(0.5),\n",
        "    # transforms.ColorJitter(brightness=0.5,contrast=0.2,saturation=0.1,hue=0.2),\n",
        "    transforms.RandomVerticalFlip(0.5),\n",
        "    # transforms.ColorJitter(brightness=0.5,contrast=0.2,saturation=0.1,hue=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "\n",
        "# # Load dataset\n",
        "\n",
        "dataset = datasets.ImageFolder('/content/Multiclass/Multi-Class(Pens,Mechanical,Wooden)',\n",
        "                               transform=transform)\n",
        "\n",
        "train_set = datasets.ImageFolder(\n",
        "    '/content/Multiclass/Multi-Class(Pens,Mechanical,Wooden)/Train',  # Adjust path to your images folder\n",
        "    transform=transform\n",
        ")\n",
        "validatation_set = datasets.ImageFolder(\n",
        "    '/content/Multiclass/Multi-Class(Pens,Mechanical,Wooden)/Validation',  # Adjust path to your images folder\n",
        "    transform=transform\n",
        ")\n",
        "test_set = datasets.ImageFolder(\n",
        "    '/content/Multiclass/Multi-Class(Pens,Mechanical,Wooden)/Test',  # Adjust path to your images folder\n",
        "    transform=transform\n",
        ")\n",
        "# # # Split into train/test sets\n",
        "# train_size = int(0.8 * len(dataset))\n",
        "# test_size = len(dataset) - train_size\n",
        "# train_set, test_set = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# # Create DataLoaders\n",
        "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "validatation_loader = DataLoader(validatation_set, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=32, shuffle=False)\n",
        "loaders = {'train':train_loader,\n",
        "          'validation': validatation_loader,\n",
        "          'test': test_loader\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# # Load dataset\n",
        "\n",
        "dataset = datasets.ImageFolder('/content/Multiclass/Multi-Class(Pens,Mechanical,Wooden)',\n",
        "                               transform=transform)\n",
        "\n",
        "train_set = datasets.ImageFolder(\n",
        "    '/content/Multiclass/Multi-Class(Pens,Mechanical,Wooden)/Train',  # Adjust path to your images folder\n",
        "    transform=transform\n",
        ")\n",
        "validatation_set = datasets.ImageFolder(\n",
        "    '/content/Multiclass/Multi-Class(Pens,Mechanical,Wooden)/Validation',  # Adjust path to your images folder\n",
        "    transform=transform\n",
        ")\n",
        "test_set = datasets.ImageFolder(\n",
        "    '/content/Multiclass/Multi-Class(Pens,Mechanical,Wooden)/Test',  # Adjust path to your images folder\n",
        "    transform=transform\n",
        ")\n",
        "# # # Split into train/test sets\n",
        "# train_size = int(0.8 * len(dataset))\n",
        "# test_size = len(dataset) - train_size\n",
        "# train_set, test_set = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# # Create DataLoaders\n",
        "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "validatation_loader = DataLoader(validatation_set, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=32, shuffle=False)\n",
        "loaders = {'train':train_loader,\n",
        "          'validation': validatation_loader,\n",
        "          'test': test_loader\n",
        "}\n",
        "class_name = train_set.classes"
      ],
      "metadata": {
        "id": "Wbq4tkpP9VXJ"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = ''\n",
        "if (torch.cuda.is_available()):\n",
        "  device = 'cuda'\n",
        "else:\n",
        "  device = 'cpu'\n",
        "\n",
        "model = ModelClassifier().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001,weight_decay=0.00001)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
        "# optimizer = nn.optim.Adam(model_parameters(), lr = 0.001)\n",
        "\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def validate(model,val_loader,loss_fn):\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in val_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            val_loss += loss_fn(output, target).item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            total += target.size(0)\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    accuracy = 100. * correct / total\n",
        "\n",
        "    return val_loss, accuracy\n",
        "\n",
        "def train(model,epochs,patience=5):\n",
        "    best_val_loss = float('inf')\n",
        "    best_model_weights = None\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = loss_fn(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            total += target.size(0)\n",
        "\n",
        "            if batch_idx % 10 == 0:\n",
        "                print(f'Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders[\"train\"].dataset)} '\n",
        "                      f'({100. * batch_idx / len(loaders[\"train\"]):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
        "\n",
        "        # Validation phase\n",
        "        val_loss, val_acc = validate(model, loaders['validation'], loss_fn)\n",
        "        train_loss /= len(loaders['train'])\n",
        "        train_acc = 100. * correct / total\n",
        "\n",
        "        print(f'\\nEpoch {epoch}:')\n",
        "        print(f'Train Loss: {train_loss:.4f} | Accuracy: {train_acc:.2f}%')\n",
        "        print(f'Val Loss: {val_loss:.4f} | Accuracy: {val_acc:.2f}%')\n",
        "\n",
        "        # Learning rate scheduling\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        # Early stopping check\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model_weights = model.state_dict()\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "            print(f'Validation loss improved. Model saved.')\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            print(f'No improvement in validation loss for {epochs_no_improve} epochs')\n",
        "            if epochs_no_improve >= patience:\n",
        "                print(f'Early stopping after {epoch} epochs')\n",
        "                break\n",
        "\n",
        "    # Load best model weights\n",
        "    model.load_state_dict(best_model_weights)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "NThYhl2P0oOA"
      },
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "\n",
        "def test_model(model, test_loader, print_samples=5):\n",
        "    model.eval()\n",
        "    class_names = test_loader.dataset.classes\n",
        "    num_classes = len(class_names)\n",
        "\n",
        "    # Initialize counters\n",
        "    class_correct = [0] * num_classes\n",
        "    class_total = [0] * num_classes\n",
        "    samples_shown = 0\n",
        "\n",
        "    print(\"\\nTesting model...\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            # Update statistics\n",
        "            for label, prediction in zip(labels, predicted):\n",
        "                class_total[label] += 1\n",
        "                if label == prediction:\n",
        "                    class_correct[label] += 1\n",
        "\n",
        "            # Print balanced samples\n",
        "            if samples_shown < print_samples:\n",
        "                for i in range(len(images)):\n",
        "                    if samples_shown >= print_samples:\n",
        "                        break\n",
        "                    if class_total[labels[i].item()] <= print_samples//num_classes:\n",
        "                        pred_name = class_names[predicted[i].item()]\n",
        "                        true_name = class_names[labels[i].item()]\n",
        "                        correct_str = \"✓\" if predicted[i] == labels[i] else \"✗\"\n",
        "                        print(f\"  {correct_str} Pred: {pred_name:<15} (True: {true_name})\")\n",
        "                        samples_shown += 1\n",
        "\n",
        "    # Calculate overall and per-class accuracy\n",
        "    total_correct = sum(class_correct)\n",
        "    total = sum(class_total)\n",
        "    overall_accuracy = 100 * total_correct / total\n",
        "\n",
        "    print(\"\\nClass-wise Performance:\")\n",
        "    print(\"-\" * 50)\n",
        "    for i in range(num_classes):\n",
        "        accuracy = 100 * class_correct[i] / class_total[i] if class_total[i] > 0 else 0\n",
        "        print(f\"{class_names[i]:<15}: {accuracy:.2f}% ({class_correct[i]}/{class_total[i]})\")\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"\\nOverall Accuracy: {overall_accuracy:.2f}% ({total_correct}/{total})\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    return overall_accuracy"
      ],
      "metadata": {
        "id": "rft0Ec1i7Ep8"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_confusion_matrix_manual(model, test_loader, num_classes, device):\n",
        "    model.eval()\n",
        "    confusion_matrix = torch.zeros(num_classes, num_classes)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, labels in test_loader:\n",
        "            data = data.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(data)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for t, p in zip(labels.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "    # Normalize the confusion matrix\n",
        "    cm_normalized = confusion_matrix / confusion_matrix.sum(1).view(-1, 1)\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(cm_normalized.numpy(), interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.colorbar()\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.ylabel('True label')\n",
        "    plt.xticks(torch.arange(num_classes))\n",
        "    plt.yticks(torch.arange(num_classes))\n",
        "\n",
        "    # Add text annotations\n",
        "    thresh = cm_normalized.max() / 2.\n",
        "    for i in range(num_classes):\n",
        "        for j in range(num_classes):\n",
        "            plt.text(j, i, f\"{confusion_matrix[i, j]:.0f}\\n({cm_normalized[i, j]*100:.1f}%)\",\n",
        "                    horizontalalignment=\"center\",\n",
        "                    color=\"white\" if cm_normalized[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return confusion_matrix"
      ],
      "metadata": {
        "id": "vUsb__ppDUpa"
      },
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model,20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDayv8TQ338s",
        "outputId": "f3c46a94-0aad-4cf0-df01-c8b5534d2563"
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 [0/404 (0%)]\tLoss: 1.452231\n",
            "Epoch: 1 [320/404 (77%)]\tLoss: 1.372792\n",
            "\n",
            "Epoch 1:\n",
            "Train Loss: 1.4997 | Accuracy: 24.50%\n",
            "Val Loss: 1.3897 | Accuracy: 26.14%\n",
            "Validation loss improved. Model saved.\n",
            "Epoch: 2 [0/404 (0%)]\tLoss: 1.513132\n",
            "Epoch: 2 [320/404 (77%)]\tLoss: 1.180051\n",
            "\n",
            "Epoch 2:\n",
            "Train Loss: 1.3222 | Accuracy: 34.41%\n",
            "Val Loss: 1.4258 | Accuracy: 26.14%\n",
            "No improvement in validation loss for 1 epochs\n",
            "Epoch: 3 [0/404 (0%)]\tLoss: 1.278960\n",
            "Epoch: 3 [320/404 (77%)]\tLoss: 1.273756\n",
            "\n",
            "Epoch 3:\n",
            "Train Loss: 1.2294 | Accuracy: 43.07%\n",
            "Val Loss: 1.3497 | Accuracy: 39.77%\n",
            "Validation loss improved. Model saved.\n",
            "Epoch: 4 [0/404 (0%)]\tLoss: 1.219014\n",
            "Epoch: 4 [320/404 (77%)]\tLoss: 1.101748\n",
            "\n",
            "Epoch 4:\n",
            "Train Loss: 1.1423 | Accuracy: 51.98%\n",
            "Val Loss: 1.3939 | Accuracy: 36.36%\n",
            "No improvement in validation loss for 1 epochs\n",
            "Epoch: 5 [0/404 (0%)]\tLoss: 1.136397\n",
            "Epoch: 5 [320/404 (77%)]\tLoss: 1.170489\n",
            "\n",
            "Epoch 5:\n",
            "Train Loss: 1.0538 | Accuracy: 52.48%\n",
            "Val Loss: 1.4100 | Accuracy: 52.27%\n",
            "No improvement in validation loss for 2 epochs\n",
            "Epoch: 6 [0/404 (0%)]\tLoss: 0.944288\n",
            "Epoch: 6 [320/404 (77%)]\tLoss: 0.843835\n",
            "\n",
            "Epoch 6:\n",
            "Train Loss: 0.9617 | Accuracy: 61.63%\n",
            "Val Loss: 1.5164 | Accuracy: 36.36%\n",
            "No improvement in validation loss for 3 epochs\n",
            "Epoch: 7 [0/404 (0%)]\tLoss: 0.884852\n",
            "Epoch: 7 [320/404 (77%)]\tLoss: 0.739038\n",
            "\n",
            "Epoch 7:\n",
            "Train Loss: 0.9306 | Accuracy: 58.91%\n",
            "Val Loss: 1.4885 | Accuracy: 39.77%\n",
            "No improvement in validation loss for 4 epochs\n",
            "Epoch: 8 [0/404 (0%)]\tLoss: 1.005580\n",
            "Epoch: 8 [320/404 (77%)]\tLoss: 0.650445\n",
            "\n",
            "Epoch 8:\n",
            "Train Loss: 0.8231 | Accuracy: 70.54%\n",
            "Val Loss: 1.4152 | Accuracy: 62.50%\n",
            "No improvement in validation loss for 5 epochs\n",
            "Early stopping after 8 epochs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModelClassifier(\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv3): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv4): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (drop): Dropout(p=0.5, inplace=False)\n",
              "  (dense): Linear(in_features=8192, out_features=300, bias=True)\n",
              "  (out): Linear(in_features=300, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 234
        }
      ]
    },
    {
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "\n",
        "def predict_custom_image(model, image_path, class_names):\n",
        "    \"\"\"\n",
        "    Predict image class with automatic device detection (CUDA if available, otherwise CPU)\n",
        "\n",
        "    Args:\n",
        "        model: Trained PyTorch model\n",
        "        image_path: Path to image file\n",
        "        class_names: List of class names (order must match training)\n",
        "\n",
        "    Returns:\n",
        "        tuple: (predicted_class, confidence, all_probs)\n",
        "    \"\"\"\n",
        "    # Set device automatically\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Model setup\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Preprocessing - MUST MATCH TRAINING PREPROCESSING\n",
        "    # Use the same transformations as used for training data loaders\n",
        "    transform = transforms.Compose([\n",
        "      # transforms.Grayscale(),  # if not already grayscale\n",
        "      transforms.Resize((128, 128)),  # resize if needed\n",
        "      # transforms.RandomResizedCrop(size=128,scale=(0.8,1.0)),\n",
        "      transforms.RandomHorizontalFlip(0.5),\n",
        "      # transforms.ColorJitter(brightness=0.5,contrast=0.2,saturation=0.1,hue=0.2),\n",
        "      transforms.RandomVerticalFlip(0.5),\n",
        "      # transforms.ColorJitter(brightness=0.5,contrast=0.2,saturation=0.1,hue=0.2),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "    try:\n",
        "        # Load and preprocess image\n",
        "        # Remove .convert('RGB') to allow transforms.Grayscale() to work correctly\n",
        "        img = Image.open(image_path)\n",
        "        img_tensor = transform(img).unsqueeze(0).to(device)  # Add batch dimension\n",
        "\n",
        "        # Prediction\n",
        "        with torch.no_grad():\n",
        "            output = model(img_tensor)\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = torch.nn.functional.softmax(output[0], dim=0)\n",
        "            conf, pred_idx = torch.max(probs, 0)\n",
        "\n",
        "        # Prepare results\n",
        "        all_probs = {class_names[i]: f\"{probs[i].item()*100:.1f}%\"\n",
        "                    for i in range(len(class_names))}\n",
        "\n",
        "        return class_names[pred_idx], conf.item(), all_probs\n",
        "\n",
        "    except Exception as e:\n",
        "        # Re-raise the exception with a more informative message\n",
        "        raise RuntimeError(f\"Prediction failed: {str(e)}\")\n",
        "\n",
        "\n",
        "# Example usage\n",
        "# Make sure 'dataset' is the ImageFolder instance you want to use for getting class names\n",
        "# In your setup, 'dataset' is created directly under Custom_DataSet, while test_set is\n",
        "# created under Custom_DataSet/Test. For prediction on individual images, it's often\n",
        "# convenient to use a dataset object that reflects the classes you trained on.\n",
        "# Using 'train_set' or 'test_set' here would also work as they share the same class structure\n",
        "# derived from the subfolders. Let's use train_set as it's generally available.\n",
        "# However, the original code uses 'dataset' from the root, which should also work\n",
        "# if the root contains subfolders corresponding to the classes. Let's stick to 'dataset'\n",
        "# as per the original error context.\n",
        "\n",
        "# Ensure the device variable is defined (it is in your global variables)\n",
        "# device = 'cuda' if torch.cuda.is_available() else 'cpu' # This is defined earlier in your notebook\n",
        "\n",
        "# Ensure the dataset object is available and correctly instantiated ImageFolder\n",
        "# dataset = datasets.ImageFolder('/content/Pens_Pencils/Custom_DataSet', transform=transform) # This is defined earlier\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "NQp-9N7V-VHw"
      },
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Define a dictionary to store layer outputs\n",
        "layer_outputs = {}\n",
        "\n",
        "def get_layer_output(name):\n",
        "    \"\"\"Hook function to store layer output\"\"\"\n",
        "    def hook(model, input, output):\n",
        "        layer_outputs[name] = output.detach()\n",
        "    return hook\n",
        "\n",
        "def predict_with_debug(model, image_path, class_names):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Register hooks for all layers\n",
        "    hooks = []\n",
        "    for name, layer in model.named_children():\n",
        "        hook = layer.register_forward_hook(get_layer_output(name))\n",
        "        hooks.append(hook)\n",
        "\n",
        "    # Preprocess image\n",
        "    transform = transforms.Compose([\n",
        "      # transforms.Grayscale(),  # if not already grayscale\n",
        "      transforms.Resize((128, 128)),  # resize if needed\n",
        "      # transforms.RandomResizedCrop(size=128,scale=(0.8,1.0)),\n",
        "      transforms.RandomHorizontalFlip(0.5),\n",
        "      # transforms.ColorJitter(brightness=0.5,contrast=0.2,saturation=0.1,hue=0.2),\n",
        "      transforms.RandomVerticalFlip(0.5),\n",
        "      # transforms.ColorJitter(brightness=0.5,contrast=0.2,saturation=0.1,hue=0.2),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "    img = Image.open(image_path)\n",
        "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "    # Forward pass (captures all layer outputs in `layer_outputs`)\n",
        "    with torch.no_grad():\n",
        "        output = model(img_tensor)\n",
        "        probs = torch.nn.functional.softmax(output[0], dim=0)\n",
        "        conf, pred_idx = torch.max(probs, 0)\n",
        "\n",
        "    # Remove hooks\n",
        "    for hook in hooks:\n",
        "        hook.remove()\n",
        "\n",
        "    # Print layer outputs (for debugging)\n",
        "    for name, output in layer_outputs.items():\n",
        "        print(f\"Layer: {name}\")\n",
        "        print(f\"Shape: {output.shape}\")\n",
        "        print(f\"Min: {output.min().item()}, Max: {output.max().item()}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    # Return prediction results\n",
        "    all_probs = {class_names[i]: f\"{probs[i].item()*100:.1f}%\"\n",
        "                for i in range(len(class_names))}\n",
        "    return class_names[pred_idx], conf.item(), all_probs"
      ],
      "metadata": {
        "id": "XUsZPPM76kSP"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(model,test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqpisB9O7MEk",
        "outputId": "b8e8a3fe-de0d-495a-9079-c41b6ae4d0de"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing model...\n",
            "--------------------------------------------------\n",
            "\n",
            "Class-wise Performance:\n",
            "--------------------------------------------------\n",
            "Crayon         : 60.87% (14/23)\n",
            "Marker         : 78.26% (18/23)\n",
            "Pen            : 52.38% (11/21)\n",
            "Wooden_Pencil  : 90.48% (19/21)\n",
            "--------------------------------------------------\n",
            "\n",
            "Overall Accuracy: 70.45% (62/88)\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70.45454545454545"
            ]
          },
          "metadata": {},
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "create_confusion_matrix_manual(model,test_loader=test_loader,num_classes=4,device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "5B2bOp-oDXSO",
        "outputId": "10086f24-540f-4231-ecaa-42b744267445"
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[14.,  7.,  1.,  1.],\n",
              "        [ 5., 15.,  3.,  0.],\n",
              "        [ 0.,  3., 11.,  7.],\n",
              "        [ 2.,  0.,  2., 17.]])"
            ]
          },
          "metadata": {},
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model,'Pen_and_Pencil_md.pth')"
      ],
      "metadata": {
        "id": "y8_GHhlPQhzs"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume `model` is an instance of a torch.nn.Module\n",
        "torch.save(model.state_dict(), \"Multi_class_md.pth\")\n"
      ],
      "metadata": {
        "id": "hbi3w5cRD1pa"
      },
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "example_classes = test_loader.dataset.classes\n",
        "\n",
        "pred_class, confidence, all_probs = predict_custom_image(\n",
        "            model=model,\n",
        "            image_path='/content/pencil_280523090.jpg',\n",
        "            class_names=example_classes\n",
        "        )\n",
        "\n",
        "print(f\"\\nPrediction Results:\")\n",
        "print(f\"Most likely: {pred_class} ({confidence*100:.2f}% confidence)\")\n",
        "print(\"\\nAll class probabilities:\")\n",
        "for cls, prob in all_probs.items():\n",
        "    print(f\"{cls}: {prob}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJ9m3kM-Xvo4",
        "outputId": "9b1c7d6e-20af-475c-8883-fc332d3587ce"
      },
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "\n",
            "Prediction Results:\n",
            "Most likely: Pen (52.63% confidence)\n",
            "\n",
            "All class probabilities:\n",
            "Crayon: 5.2%\n",
            "Marker: 8.1%\n",
            "Pen: 52.6%\n",
            "Wooden_Pencil: 34.1%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "example_classes = test_loader.dataset.classes\n",
        "\n",
        "pred_class, confidence, all_probs = predict_custom_image(\n",
        "            model=model,\n",
        "            image_path='/content/CrayonTest.jpg',\n",
        "            class_names=example_classes\n",
        "        )\n",
        "\n",
        "print(f\"\\nPrediction Results:\")\n",
        "print(f\"Most likely: {pred_class} ({confidence*100:.2f}% confidence)\")\n",
        "print(\"\\nAll class probabilities:\")\n",
        "for cls, prob in all_probs.items():\n",
        "    print(f\"{cls}: {prob}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35c2050e-81a0-4792-a41f-4ff70b88627e",
        "id": "isvdYbDyAm1S"
      },
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "\n",
            "Prediction Results:\n",
            "Most likely: Pen (77.88% confidence)\n",
            "\n",
            "All class probabilities:\n",
            "Crayon: 0.3%\n",
            "Marker: 19.8%\n",
            "Pen: 77.9%\n",
            "Wooden_Pencil: 2.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pen Test\n",
        "example_classes = test_loader.dataset.classes\n",
        "\n",
        "pred_class, confidence, all_probs = predict_custom_image(\n",
        "            model=model,\n",
        "            image_path='/content/51TkKa5QdgL.jpg',\n",
        "            class_names=example_classes\n",
        "        )\n",
        "\n",
        "print(f\"\\nPrediction Results:\")\n",
        "print(f\"Most likely: {pred_class} ({confidence*100:.2f}% confidence)\")\n",
        "print(\"\\nAll class probabilities:\")\n",
        "for cls, prob in all_probs.items():\n",
        "    print(f\"{cls}: {prob}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d99aa3b3-54a5-45d6-c8e0-f4e309d3925f",
        "id": "wvFn47OAB6zE"
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "\n",
            "Prediction Results:\n",
            "Most likely: Pen (59.37% confidence)\n",
            "\n",
            "All class probabilities:\n",
            "Crayon: 2.9%\n",
            "Marker: 35.9%\n",
            "Pen: 59.4%\n",
            "Wooden_Pencil: 1.9%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kkgN_jXR8USJ"
      },
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "example_classes = test_loader.dataset.classes\n",
        "\n",
        "pred_class, confidence, all_probs = predict_custom_image(\n",
        "            model=model,\n",
        "            image_path='/content/markertest2.jpg',\n",
        "            class_names=example_classes\n",
        "        )\n",
        "\n",
        "print(f\"\\nPrediction Results:\")\n",
        "print(f\"Most likely: {pred_class} ({confidence*100:.2f}% confidence)\")\n",
        "print(\"\\nAll class probabilities:\")\n",
        "for cls, prob in all_probs.items():\n",
        "    print(f\"{cls}: {prob}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7aa4c71-d4f2-452a-b4c2-4e7e05b461ff",
        "id": "tZRPJdRgutzF"
      },
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "\n",
            "Prediction Results:\n",
            "Most likely: Pen (58.36% confidence)\n",
            "\n",
            "All class probabilities:\n",
            "Crayon: 7.8%\n",
            "Marker: 23.1%\n",
            "Pen: 58.4%\n",
            "Wooden_Pencil: 10.7%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "example_classes = test_loader.dataset.classes\n",
        "\n",
        "pred_class, confidence, all_probs = predict_custom_image(\n",
        "            model=model,\n",
        "            image_path='/content/tough_crayon.jpg',\n",
        "            class_names=example_classes\n",
        "        )\n",
        "\n",
        "print(f\"\\nPrediction Results:\")\n",
        "print(f\"Most likely: {pred_class} ({confidence*100:.2f}% confidence)\")\n",
        "print(\"\\nAll class probabilities:\")\n",
        "for cls, prob in all_probs.items():\n",
        "    print(f\"{cls}: {prob}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cfd8223-4262-4fd4-fde0-7091c4882254",
        "id": "_fsg3a4t8ll7"
      },
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "\n",
            "Prediction Results:\n",
            "Most likely: Pen (89.97% confidence)\n",
            "\n",
            "All class probabilities:\n",
            "Crayon: 2.3%\n",
            "Marker: 3.6%\n",
            "Pen: 90.0%\n",
            "Wooden_Pencil: 4.1%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1 Example (Both Pen and Pencil) usage\n",
        "example_classes = test_loader.dataset.classes\n",
        "\n",
        "pred_class, confidence, all_probs = predict_custom_image(\n",
        "            model=model,\n",
        "            image_path='/content/bicppp-07-mm.jpg',\n",
        "            class_names=example_classes\n",
        "        )\n",
        "\n",
        "print(f\"\\nPrediction Results:\")\n",
        "print(f\"Most likely: {pred_class} ({confidence*100:.2f}% confidence)\")\n",
        "print(\"\\nAll class probabilities:\")\n",
        "for cls, prob in all_probs.items():\n",
        "    print(f\"{cls}: {prob}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "outputId": "603d8ccb-8df2-44a7-e3ff-63e8748b53c9",
        "id": "Bwor7Gn7v2kK"
      },
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Prediction failed: [Errno 2] No such file or directory: '/content/bicppp-07-mm.jpg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-235-ec8a1ce243af>\u001b[0m in \u001b[0;36mpredict_custom_image\u001b[0;34m(model, image_path, class_names)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# Remove .convert('RGB') to allow transforms.Grayscale() to work correctly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mimg_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Add batch dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3504\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3505\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3506\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/bicppp-07-mm.jpg'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-246-a9b1b05698ef>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mexample_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m pred_class, confidence, all_probs = predict_custom_image(\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mimage_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/bicppp-07-mm.jpg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-235-ec8a1ce243af>\u001b[0m in \u001b[0;36mpredict_custom_image\u001b[0;34m(model, image_path, class_names)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Re-raise the exception with a more informative message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Prediction failed: {str(e)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Prediction failed: [Errno 2] No such file or directory: '/content/bicppp-07-mm.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1 Example (Both Pen and Pencil) usage\n",
        "example_classes = test_loader.dataset.classes\n",
        "\n",
        "pred_class, confidence, all_probs = predict_custom_image(\n",
        "            model=model,\n",
        "            image_path='/content/332947.jpg',\n",
        "            class_names=example_classes\n",
        "        )\n",
        "\n",
        "print(f\"\\nPrediction Results:\")\n",
        "print(f\"Most likely: {pred_class} ({confidence*100:.2f}% confidence)\")\n",
        "print(\"\\nAll class probabilities:\")\n",
        "for cls, prob in all_probs.items():\n",
        "    print(f\"{cls}: {prob}\")\n"
      ],
      "metadata": {
        "id": "7-Wd1svNtJQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example (Both Pen and Pencil) usage\n",
        "example_classes = test_loader.dataset.classes\n",
        "\n",
        "pred_class, confidence, all_probs = predict_custom_image(\n",
        "            model=model,\n",
        "            image_path='/content/Example_1.jpg',\n",
        "            class_names=example_classes\n",
        "        )\n",
        "\n",
        "print(f\"\\nPrediction Results:\")\n",
        "print(f\"Most likely: {pred_class} ({confidence*100:.2f}% confidence)\")\n",
        "print(\"\\nAll class probabilities:\")\n",
        "for cls, prob in all_probs.items():\n",
        "    print(f\"{cls}: {prob}\")"
      ],
      "metadata": {
        "id": "nUn7wS-7v2UU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2 Example (Both Pen and Pencil) usage\n",
        "example_classes = test_loader.dataset.classes\n",
        "\n",
        "pred_class, confidence, all_probs = predict_custom_image(\n",
        "            model=model,\n",
        "            image_path='/content/Example_2.png',\n",
        "            class_names=example_classes\n",
        "        )\n",
        "\n",
        "print(f\"\\nPrediction Results:\")\n",
        "print(f\"Most likely: {pred_class} ({confidence*100:.2f}% confidence)\")\n",
        "print(\"\\nAll class probabilities:\")\n",
        "for cls, prob in all_probs.items():\n",
        "    print(f\"{cls}: {prob}\")\n"
      ],
      "metadata": {
        "id": "yz3BQGHBv2zD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "example_classes = test_loader.dataset.classes\n",
        "\n",
        "pred_class, confidence, all_probs = predict_custom_image(\n",
        "            model=model,\n",
        "            image_path='/content/TTT.jpg',\n",
        "            class_names=example_classes\n",
        "        )\n",
        "\n",
        "print(f\"\\nPrediction Results:\")\n",
        "print(f\"Most likely: {pred_class} ({confidence*100:.2f}% confidence)\")\n",
        "print(\"\\nAll class probabilities:\")\n",
        "for cls, prob in all_probs.items():\n",
        "    print(f\"{cls}: {prob}\")\n"
      ],
      "metadata": {
        "id": "gXkGkojNvSAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "example_classes = test_loader.dataset.classes\n",
        "\n",
        "pred_class, confidence, all_probs = predict_custom_image(\n",
        "            model=model,\n",
        "            image_path='/content/71uPkyrlipL.jpg',\n",
        "            class_names=example_classes\n",
        "        )\n",
        "\n",
        "print(f\"\\nPrediction Results:\")\n",
        "print(f\"Most likely: {pred_class} ({confidence*100:.2f}% confidence)\")\n",
        "print(\"\\nAll class probabilities:\")\n",
        "for cls, prob in all_probs.items():\n",
        "    print(f\"{cls}: {prob}\")\n"
      ],
      "metadata": {
        "id": "h3vUsdLOveox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "example_classes = test_loader.dataset.classes\n",
        "\n",
        "pred_class, confidence, all_probs = predict_custom_image(\n",
        "            model=model,\n",
        "            image_path='/content/tip.jpg',\n",
        "            class_names=example_classes\n",
        "        )\n",
        "\n",
        "print(f\"\\nPrediction Results:\")\n",
        "print(f\"Most likely: {pred_class} ({confidence*100:.2f}% confidence)\")\n",
        "print(\"\\nAll class probabilities:\")\n",
        "for cls, prob in all_probs.items():\n",
        "    print(f\"{cls}: {prob}\")\n"
      ],
      "metadata": {
        "id": "RLw_u57-S5nX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "example_classes = test_loader.dataset.classes\n",
        "\n",
        "pred_class, confidence, all_probs = predict_custom_image(\n",
        "            model=model,\n",
        "            image_path='/content/Test_end.jpg',\n",
        "            class_names=example_classes\n",
        "        )\n",
        "\n",
        "print(f\"\\nPrediction Results:\")\n",
        "print(f\"Most likely: {pred_class} ({confidence*100:.2f}% confidence)\")\n",
        "print(\"\\nAll class probabilities:\")\n",
        "for cls, prob in all_probs.items():\n",
        "    print(f\"{cls}: {prob}\")\n"
      ],
      "metadata": {
        "id": "HqrEec9ES6I1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "example_classes = test_loader.dataset.classes\n",
        "\n",
        "pred_class, confidence, all_probs = predict_custom_image(\n",
        "            model=model,\n",
        "            image_path='/content/ue2ilgr1xau21.jpg',\n",
        "            class_names=example_classes\n",
        "        )\n",
        "\n",
        "print(f\"\\nPrediction Results:\")\n",
        "print(f\"Most likely: {pred_class} ({confidence*100:.2f}% confidence)\")\n",
        "print(\"\\nAll class probabilities:\")\n",
        "for cls, prob in all_probs.items():\n",
        "    print(f\"{cls}: {prob}\")\n"
      ],
      "metadata": {
        "id": "3VIxxF7FUQBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "example_classes = test_loader.dataset.classes\n",
        "\n",
        "pred_class, confidence, all_probs = predict_custom_image(\n",
        "            model=model,\n",
        "            image_path='/content/bud.jpg',\n",
        "            class_names=example_classes\n",
        "        )\n",
        "\n",
        "print(f\"\\nPrediction Results:\")\n",
        "print(f\"Most likely: {pred_class} ({confidence*100:.2f}% confidence)\")\n",
        "print(\"\\nAll class probabilities:\")\n",
        "for cls, prob in all_probs.items():\n",
        "    print(f\"{cls}: {prob}\")\n"
      ],
      "metadata": {
        "id": "4yyqxWR_B67W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "example_classes = test_loader.dataset.classes\n",
        "\n",
        "pred_class, confidence, all_probs = predict_custom_image(\n",
        "            model=model,\n",
        "            image_path='/content/image-asset.jpeg',\n",
        "            class_names=example_classes\n",
        "        )\n",
        "\n",
        "print(f\"\\nPrediction Results:\")\n",
        "print(f\"Most likely: {pred_class} ({confidence*100:.2f}% confidence)\")\n",
        "print(\"\\nAll class probabilities:\")\n",
        "for cls, prob in all_probs.items():\n",
        "    print(f\"{cls}: {prob}\")\n"
      ],
      "metadata": {
        "id": "CVKlTjEOD85p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "example_classes = test_loader.dataset.classes\n",
        "\n",
        "pred_class, confidence, all_probs = predict_custom_image(\n",
        "            model=model,\n",
        "            image_path='/content/4539621__64029.jpg',\n",
        "            class_names=example_classes\n",
        "        )\n",
        "\n",
        "print(f\"\\nPrediction Results:\")\n",
        "print(f\"Most likely: {pred_class} ({confidence*100:.2f}% confidence)\")\n",
        "print(\"\\nAll class probabilities:\")\n",
        "for cls, prob in all_probs.items():\n",
        "    print(f\"{cls}: {prob}\")\n"
      ],
      "metadata": {
        "id": "VirqIhyREOSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w-HZ2O3N7j2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "example_classes = test_loader.dataset.classes\n",
        "\n",
        "pred_class, confidence, all_probs = predict_custom_image(\n",
        "            model=model,\n",
        "            image_path='/content/Ohto_2_Eraser_Refill.jpg',\n",
        "            class_names=example_classes\n",
        "        )\n",
        "\n",
        "print(f\"\\nPrediction Results:\")\n",
        "print(f\"Most likely: {pred_class} ({confidence*100:.2f}% confidence)\")\n",
        "print(\"\\nAll class probabilities:\")\n",
        "for cls, prob in all_probs.items():\n",
        "    print(f\"{cls}: {prob}\")\n"
      ],
      "metadata": {
        "id": "ZLcYdEv1EOaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_classes = test_loader.dataset.classes\n",
        "\n",
        "pred_class, confidence, all_probs = predict_with_debug(\n",
        "            model=model,\n",
        "            image_path='/content/Ohto_2_Eraser_Refill.jpg',\n",
        "            class_names=example_classes\n",
        "        )\n",
        "\n",
        "print(f\"\\nPrediction Results:\")\n",
        "print(f\"Most likely: {pred_class} ({confidence*100:.2f}% confidence)\")\n",
        "print(\"\\nAll class probabilities:\")\n",
        "for cls, prob in all_probs.items():\n",
        "    print(f\"{cls}: {prob}\")"
      ],
      "metadata": {
        "id": "WkBa7bAt91Gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_classes = test_loader.dataset.classes\n",
        "\n",
        "pred_class, confidence, all_probs = predict_with_debug(\n",
        "            model=model,\n",
        "            image_path='/content/pc.jpg',\n",
        "            class_names=example_classes\n",
        "        )\n",
        "\n",
        "print(f\"\\nPrediction Results:\")\n",
        "print(f\"Most likely: {pred_class} ({confidence*100:.2f}% confidence)\")\n",
        "print(\"\\nAll class probabilities:\")\n",
        "for cls, prob in all_probs.items():\n",
        "    print(f\"{cls}: {prob}\")"
      ],
      "metadata": {
        "id": "6Ges6x9X8-pT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_classes = test_loader.dataset.classes\n",
        "\n",
        "pred_class, confidence, all_probs = predict_with_debug(\n",
        "            model=model,\n",
        "            image_path='/content/610qJ+apPML._AC_UF1000,1000_QL80_.jpg',\n",
        "            class_names=example_classes\n",
        "        )\n",
        "\n",
        "print(f\"\\nPrediction Results:\")\n",
        "print(f\"Most likely: {pred_class} ({confidence*100:.2f}% confidence)\")\n",
        "print(\"\\nAll class probabilities:\")\n",
        "for cls, prob in all_probs.items():\n",
        "    print(f\"{cls}: {prob}\")"
      ],
      "metadata": {
        "id": "6NoO9dFW9Ee7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}